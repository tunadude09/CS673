{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# package edu.michigan.gevirtz.data;\n",
    "\n",
    "# import java.util.Arrays;\n",
    "\n",
    "class DataVector:\n",
    "    def __init__(self, values):\n",
    "        self.label = -1\n",
    "        self.values = values\n",
    "\n",
    "    def setValues(self, values):\n",
    "        self.values = values\n",
    "    \n",
    "    def getValues(self):\n",
    "        return self.values\n",
    "    \n",
    "    def setLabel(self, label):\n",
    "        self.label = label\n",
    "\n",
    "    def GetLabel(self):\n",
    "        return self.label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# package edu.michigan.gevirtz.optimization;\n",
    "\n",
    "# import org.jblas.DoubleMatrix;\n",
    "\n",
    "# public interface Minimizer {\n",
    "    \n",
    "#     public DoubleMatrix Minimize(OptimizationProblem problem, DoubleMatrix x0);\n",
    "\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# package edu.michigan.gevirtz.optimization;\n",
    "\n",
    "# import org.jblas.DoubleMatrix;\n",
    "\n",
    "class OptimizationProblem:\n",
    "    pass\n",
    "#     //Returns parameters to be optimized\n",
    "#     public double Function(DoubleMatrix x);\n",
    "#     public DoubleMatrix Gradient(DoubleMatrix x);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# package edu.michigan.gevirtz.optimization;\n",
    "\n",
    "# import org.jblas.DoubleMatrix;\n",
    "# import org.jblas.Solve;\n",
    "\n",
    "class BFGSOptimizer:\n",
    "    def __init__(self):\n",
    "        self.problem = None # OptimizationProblem\n",
    "        self.alpha = 0.1\n",
    "        #  number of steps in to search while doing line search for new parameter vector\n",
    "\n",
    "        self.k = 100\n",
    "\n",
    "    #Setters\n",
    "    \"\"\"\n",
    "    Sets the largest (in magnitude) alpha to be used in updating the current parameter vector \n",
    "    @param alpha\n",
    "    \"\"\"\n",
    "    def SetMaximumAlpha(self, alpha):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def SetK(self, k):\n",
    "        self.k = k\n",
    "\n",
    "\n",
    "    def GetDirection(self, B, x):\n",
    "        ***grad = self.problem.Gradient(x).mul(-1.0)\n",
    "        ***return Solve.solve(B, grad)\n",
    "\n",
    "\n",
    "\n",
    "    def PerformLineSearch(self, x, direction):\n",
    "        currentAlpha = 0\n",
    "        ***currentMinimum = Double.MAX_VALUE\n",
    "        step = self.alpha / self.k\n",
    "        ***for(int i = 1; i <= k; i++ ):\n",
    "            ***new_x = x.add(direction.mul(step * i))\n",
    "            ***val = problem.Function(new_x)\n",
    "            if val < currentMinimum:\n",
    "                currentAlpha = val\n",
    "                currentAlpha = step * i\n",
    "\n",
    "        return currentAlpha\n",
    "\n",
    "\n",
    "    ***@Override\n",
    "    def Minimize(self, problem, x0):\n",
    "\n",
    "        self.problem = problem\n",
    "\n",
    "        ***N = x0.rows\n",
    "\n",
    "        ***B = DoubleMatrix.eye(N);\n",
    "        ***x = x0.dup();\n",
    "\n",
    "#        while(problem.Gradient(x).norm2() >= .05){\n",
    "        while problem.Function(x) >= 0.05:\n",
    "            direction = self.GetDirection(B, x);\n",
    "            ***norm = direction.norm2()\n",
    "            ***direction.muli(1/norm);\n",
    "\n",
    "            alpha = self.PerformLineSearch(x, direction)\n",
    "\n",
    "            ***s = direction.mul(alpha)\n",
    "            ***x_new = x.add( s )\n",
    "\n",
    "\n",
    "            ***y = problem.Gradient(x_new).sub(  problem.Gradient(x) )\n",
    "\n",
    "            ***denominator1 = y.transpose().mmul(s).get(0)\n",
    "\n",
    "            ***denomintaor2 = s.transpose().mmul(B.mmul(s)).get(0)\n",
    "\n",
    "            ***B_new = B.add(y.mmul(y.transpose()).mul( 1 / denominator1 ))\n",
    "            ***B_new.subi(B.mmul(s.mmul(s.transpose().mmul(B))).mul( 1 / denomintaor2))\n",
    "\n",
    "            B = B_new\n",
    "            x = x_new\n",
    "\n",
    "            print(\"Grad: \"+problem.Gradient(x).norm2())\n",
    "            print(\"Func: \"+problem.Function(x))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# package edu.michigan.gevirtz.latent;\n",
    "\n",
    "# import java.awt.image.SampleModel;\n",
    "# import java.io.BufferedReader;\n",
    "# import java.io.BufferedWriter;\n",
    "# import java.io.FileReader;\n",
    "# import java.io.FileWriter;\n",
    "# import java.io.IOException;\n",
    "# import java.util.ArrayList;\n",
    "# import java.util.HashMap;\n",
    "# import java.util.List;\n",
    "# import java.util.Map;\n",
    "# import java.util.Random;\n",
    "\n",
    "# import javax.xml.crypto.Data;\n",
    "\n",
    "# import org.jblas.DoubleMatrix;\n",
    "# import org.jblas.MatrixFunctions;\n",
    "# import org.jblas.Singular;\n",
    "# import org.jblas.Solve;\n",
    "\n",
    "# import edu.michigan.gevirtz.data.DataVector;\n",
    "# import edu.michigan.gevirtz.optimization.BFGSOptimizer;\n",
    "# import edu.michigan.gevirtz.optimization.OptimizationProblem;\n",
    "\n",
    "class GTM:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data = null # List<DataVector>\n",
    "        #  holds the training data in jBLAS vectors\n",
    "        self.dataVectors = null # List<DoubleMatrix>\n",
    "        self.T = None     #  Holds the data in a matrix;\n",
    "\n",
    "        self.L = 0 # Dimensionality of latent space\n",
    "        self.M = 0 # Number of basis functions\n",
    "        self.K = 0 # Number of points in latent spaces\n",
    "        self.D = 0 # Dimensionality of observable space\n",
    "        self.N = 0\n",
    "\n",
    "        self.K_per_latent_dimension = 0\n",
    "        self.M_per_latent_dimension = 0\n",
    "\n",
    "        self.sigma = 0 # Width of gaussian basis functions\n",
    "\n",
    "        self.phiMatrix = null # Matrix containing evaluation of\n",
    "                                                # all M\n",
    "        self.W = null # Matrix defining y(x->t)\n",
    "        self.beta = 0   # variance of distribution of t\n",
    "        # basis functions on all K latent space\n",
    "        # sample points\n",
    "\n",
    "        self.basisFunctionCenters = null    # Centers for the basis\n",
    "                                                            # functions\n",
    "\n",
    "        self.latentSpaceSamplePoints = null   # Center for each x_i in the latent space\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    @param data\n",
    "    Data to train the latent model on\n",
    "    @param L\n",
    "    Dimensionality of the latent space \n",
    "    \"\"\"\n",
    "\n",
    "    def SubtractMean(data):\n",
    "        totals = new double[data.get(0).getValues().length]\n",
    "        for(int i = 0; i < data.get(0).getValues().length; i++):\n",
    "            totals[i] = 0\n",
    "        for(DataVector v : data):\n",
    "            for(int i = 0; i < v.getValues().length;i++):\n",
    "                totals[i] += v.getValues()[i]\n",
    "        for(int i = 0; i < data.get(0).getValues().length; i++):\n",
    "            totals[i] /= data.size()\n",
    "        for(int i = 0; i < data.size(); i++):\n",
    "            double [] values = data.get(i).getValues()\n",
    "            for(int j = 0; j < values.length; j++)\n",
    "                values[j] -= totals[j]\n",
    "\n",
    "#  data.remove(i);\n",
    "#  data.add(i, new DataVector(values));\n",
    "            data.get(i).SetValues(values)\n",
    "\n",
    "    def GTM(data, L):\n",
    "\n",
    "        self.SubtractMean(data);\n",
    "        self.data = data;\n",
    "\n",
    "        self.L = L;\n",
    "\n",
    "        self.N = len(data)\n",
    "\n",
    "        self.dataVectors = new ArrayList<DoubleMatrix>()\n",
    "        for(DataVector dv : data):\n",
    "            self.dataVectors.add( new DoubleMatrix(dv.getValues()) )\n",
    "\n",
    "        self.T = dataVectors.get(0).transpose();\n",
    "        for(int i = 1; i < dataVectors.size(); i++):\n",
    "            self.T = DoubleMatrix.concatVertically(self.T, dataVectors.get(i).transpose())\n",
    "\n",
    "        print(\"dataVectors.size(): \"+dataVectors.size())\n",
    "        print(\"T: \"+T.rows+\"x\"+T.columns)\n",
    "        self.D = data.get(0).getValues().length\n",
    "\n",
    "\n",
    "    # Setters\n",
    "    def setSigma(sigma):\n",
    "        self.sigma = sigma\n",
    "\n",
    "\n",
    "    def setM(M_per_latent_dimension):\n",
    "\n",
    "        self.M_per_latent_dimension = M_per_latent_dimension\n",
    "        self.M = (int) Math.pow(M_per_latent_dimension, L)\n",
    "\n",
    "\n",
    "    def setK(K_per_latent_dimension):\n",
    "\n",
    "        self.K_per_latent_dimension = K_per_latent_dimension\n",
    "        self.K = (int) Math.pow(K_per_latent_dimension, L)\n",
    "\n",
    "\n",
    "    def CalculatePhiMatrix():\n",
    "\n",
    "        phiMatrix = new DoubleMatrix(K,M);//CalculatePhiVector(latentSpaceSamplePoints[0]).transpose();\n",
    "        for(int i = 0; i < K; i++):\n",
    "            phiMatrix.putRow(i,CalculatePhiVector(latentSpaceSamplePoints[i]).transpose());\n",
    "\n",
    "            \n",
    "    def ProjectDataToLatentSpace():\n",
    "\n",
    "        return ProjectDataVectorToLatentSpace(self.data)\n",
    "            \n",
    "    def ProjectDataVectorToLatentSpace(vectors):\n",
    "        print(\"ProjectDataVectorToLatentSpace\")\n",
    "        result = new ArrayList<DataVector>()\n",
    "        print(\"\\tCalculating R...\")\n",
    "        R = CalculateR(W, beta, vectors)\n",
    "        print(\"done\")\n",
    "        N = len(vectors)\n",
    "        print(\"\\tAdding contributions...\")\n",
    "        for(int i = 0; i < N; i++):\n",
    "            vector = new DoubleMatrix(L)\n",
    "            for(int j = 0 ; j < K; j++):\n",
    "                vector.addi(latentSpaceSamplePoints[j].mul(R.get(j,i)) )\n",
    "            dv = new DataVector(vector.toArray())\n",
    "            dv.SetLabel(vectors.get(i).GetLabel())\n",
    "            result.add(dv)\n",
    "        \n",
    "        print(\"done\")\n",
    "        return result\n",
    "    \n",
    "    def ProjectToDataSpace(t):\n",
    "        return W.mmul(CalculatePhiVector(t))\n",
    "    \n",
    "\n",
    "    def CalculatePhiVector(x):\n",
    "        phi = new DoubleMatrix(M)\n",
    "        for (int i = 0; i < M; i++):\n",
    "            phi.put(i, calculateGaussian(x, basisFunctionCenters[i], sigma, L))\n",
    "        return phi\n",
    "    \n",
    "\n",
    "    # Getters\n",
    "\n",
    "    # Internal\n",
    "\n",
    "    \"\"\"\n",
    "     * Calls GenerateBasisFunctionCenters, setups up W matrix, calls\n",
    "     * CalculatePhi\n",
    "    \"\"\"\n",
    "\n",
    "    def InitializeModel():\n",
    "        print(\"Initializing model...\")\n",
    "\n",
    "        if (sigma == 0):\n",
    "            throw new RuntimeException(\n",
    "                    \"Attempted to initialize model withouth setting basis function width, sigma\");\n",
    "\n",
    "        print(\"\\tGenerating basis function centers...\")\n",
    "        GenerateBasisFunctionCenters()\n",
    "        print(\"done\")\n",
    "        print(\"\\tGenerating latent space smaple points...\")\n",
    "        GenerateLatentSpaceSamplePointCenters()\n",
    "        print(\"done\")\n",
    "        print(\"\\tCalculating phi matrix...\")\n",
    "        CalculatePhiMatrix()\n",
    "        print(\"done\")\n",
    "        \n",
    "        #Find the initial W parameters\n",
    "        W = DoubleMatrix.rand(D, M)\n",
    "        \n",
    "        paramInitializer = new ParameterInitializer(this, 2000)\n",
    "        optimizer = new BFGSOptimizer()\n",
    "        W_new = optimizer.Minimize(paramInitializer, new DoubleMatrix(W.toArray()))\n",
    "        #  Put the column-vector representation of W_new into W \n",
    "        for(int i = 0; i < D; i++):\n",
    "            for(int j = 0; j < M ; j ++):\n",
    "                W.put(i ,j , W_new.get(i * M + j))\n",
    "\n",
    "        \n",
    "        #  find initial beta parameter\n",
    "        pca = new PCA(data.subList(0, 1000))\n",
    "        \n",
    "        beta_inv = pca.GetLargestEigenvalue()\n",
    "        \n",
    "        self.beta = 1.0 / beta_inv\n",
    "        print(\"done\")\n",
    "\n",
    "\n",
    "    def CalculateDataSpaceDistribution(t, W, beta):\n",
    "        result = 0\n",
    "        for(int x_i = 0 ; x_i < K; x_i++):\n",
    "            result += CalculateDataSpaceDistribution(t, x_i, W, beta)\n",
    "        \n",
    "        return result / K\n",
    "        \n",
    "    def CalculateDataSpaceDistribution(t, x, W, beta):\n",
    "        return calculateGaussian(t, W.mmul(CalculatePhiVector(x)), beta, self.D)\n",
    "    \n",
    "    def CalculateDataSpaceDistribution(t, x_i, W, beta):\n",
    "        return calculateGaussian(t, W.mmul(phiMatrix.getRow(x_i).transpose()), beta, self.D) #  Changed from calculating phi(x_i) every thime\n",
    "    \n",
    "    def CalculateDataSpaceDistribution(t):\n",
    "        return CalculateDataSpaceDistribution(t, self.W, self.beta)\n",
    "    \n",
    "    def CalculateR(W, beta):\n",
    "        return CalculateR(W, beta, self.data)\n",
    "    \n",
    "    def CalculateR(W, beta, data):\n",
    "        N = data.size()\n",
    "        R = new DoubleMatrix(K, N)\n",
    "        \n",
    "        denominators = new double[N]\n",
    "        \n",
    "        for(int i = 0; i < N; i++):\n",
    "            vector = dataVectors.get(i)    #  Changed from creating a new thing based on the data\n",
    "            denominators[i] = CalculateDataSpaceDistribution(vector, W, beta) * K\n",
    "        \n",
    "        for(int i = 0; i < K; i++):\n",
    "            for(int j = 0; j < N; j++):\n",
    "#                vector = new DoubleMatrix(data.get(j).getValues())\n",
    "                vector = dataVectors.get(j)    #  Changed from creating a new thing based on the data\n",
    "                R.put(i,j, CalculateDataSpaceDistribution(vector, latentSpaceSamplePoints[i], W, beta) / denominators[j])\n",
    "        \n",
    "        return R\n",
    "    \n",
    "    def CalculateG(DoubleMatrix W, double beta):\n",
    "        R = CalculateR(W, beta)\n",
    "        G = new DoubleMatrix(K,K)\n",
    "\n",
    "        for(int i = 0; i < K; i++):\n",
    "            total = 0.0\n",
    "            for(int j = 0; j < N; j++):\n",
    "                total += R.get(i, j)\n",
    "            G.put(i,i,total)\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    \"\"\"\n",
    "     * Sets the lattice of basis functions\n",
    "    \"\"\"\n",
    "    def GenerateBasisFunctionCenters():\n",
    "        if (M == 0):\n",
    "            throw new RuntimeException(\n",
    "                    \"Attempted to generate basis function centers without first setting M\");\n",
    "        if (L == 0):\n",
    "            throw new RuntimeException(\n",
    "                    \"Attempted to generate basis function centers without first setting L\");\n",
    "\n",
    "        currentIndices = new int[L]\n",
    "        for (int i = 0; i < L; i++):\n",
    "            currentIndices[i] = 0\n",
    "        spacing = 2.0 / (M_per_latent_dimension - 1)\n",
    "\n",
    "        basisFunctionCenters = new DoubleMatrix[M]\n",
    "\n",
    "        for (int i = 0; i < M; i++):\n",
    "            #  update the indices\n",
    "            for (int j = 0; j < L; j++):\n",
    "                num = (int) Math.pow(M_per_latent_dimension, j)\n",
    "                currentIndices[j] = (i / num) % M_per_latent_dimension\n",
    "            \n",
    "            center = new DoubleMatrix(L)\n",
    "            #  loop through each dimension, set the position of this center for\n",
    "            #  each dimension based on the current values of \"currentIndex\"\n",
    "            for (int j = 0; j < L; j++):\n",
    "                center.put(j, spacing * currentIndices[j] - 1)\n",
    "\n",
    "#            System.out.println(\"Basis function center: \"+center)\n",
    "            basisFunctionCenters[i] = center\n",
    "            \n",
    "\n",
    "    def GenerateLatentSpaceSamplePointCenters():\n",
    "        if (K == 0):\n",
    "            throw new RuntimeException(\n",
    "                    \"Attempted to generate latent space sample point centers without first setting K\");\n",
    "        if (L == 0):\n",
    "            throw new RuntimeException(\n",
    "                    \"Attempted to generate latent space sample point centers without first setting L\");\n",
    "\n",
    "        currentIndices = new int[L]\n",
    "        for (int i = 0; i < L; i++):\n",
    "            currentIndices[i] = 0\n",
    "        spacing = 2.0 / (K_per_latent_dimension - 1)\n",
    "\n",
    "        latentSpaceSamplePoints = new DoubleMatrix[K]\n",
    "\n",
    "        for (int i = 0; i < K; i++):\n",
    "            #  update the indices\n",
    "            for (int j = 0; j < L; j++):\n",
    "                num = (int) Math.pow(K_per_latent_dimension, j)\n",
    "                currentIndices[j] = (i / num) % K_per_latent_dimension\n",
    "            \n",
    "            center = new DoubleMatrix(L)\n",
    "            # loop through each dimension, set the position of this center for\n",
    "            # each dimension based on the current values of \"currentIndex\"\n",
    "            for (int j = 0; j < L; j++):\n",
    "                center.put(j, spacing * currentIndices[j] - 1)\n",
    "#            System.out.println(\"latent space sample point: \"+center)\n",
    "            latentSpaceSamplePoints[i] = center\n",
    "    \n",
    "\n",
    "    def calculateGaussian(point, center, width, D):\n",
    "        if (point.columns != 1):\n",
    "            throw new RuntimeException(\"Point not a column vector\")\n",
    "        if (center.columns != 1):\n",
    "            throw new RuntimeException(\"Center not a column vector!\")\n",
    "        if (point.columns != center.columns):\n",
    "            throw new RuntimeException(\"Dimensions are not equal\")\n",
    "\n",
    "        return Math.pow(width / (2 * 3.14159), D / 2.0)\n",
    "                * Math.exp(-1*center.squaredDistance(point))\n",
    "\n",
    "\n",
    "    def SVDInvert(DoubleMatrix matrix):\n",
    "        svd = Singular.fullSVD(matrix)\n",
    "        \n",
    "        U = svd[0]\n",
    "        W = svd[1]\n",
    "        V = svd[2]\n",
    "        \n",
    "        W_inverse = new DoubleMatrix(W.rows, W.rows)\n",
    "        for(int i = 0; i < W.rows; i++):\n",
    "            W_inverse.put(i,i,1.0 / W.get(i,0))\n",
    "        return V.mmul(W_inverse.mmul(U.transpose()))\n",
    "\n",
    "    \n",
    "    def PerformEMStep():\n",
    "        print(\"Performing EM Step\")\n",
    "        \n",
    "        print(\"\\tCalculating R using old parameters...\")\n",
    "        R_old = CalculateR(W, beta)\n",
    "        print(\"done\")\n",
    "        print(\"\\tCalculating A using old parameters...\")\n",
    "        A = phiMatrix.transpose().mmul(CalculateG(W, beta).mmul(phiMatrix))\n",
    "        print(\"done\")\n",
    "        print(\"\\tCalculating B using old parameters...\")\n",
    "        B = phiMatrix.transpose().mmul(R_old.mmul(T))\n",
    "        print(\"done\")\n",
    "\n",
    "        print(\"\\tInverting to get new W...\")\n",
    "        W =  SVDInvert(A).mmul(B).transpose()\n",
    "        print(\"done\")\n",
    "\n",
    "        print(\"\\tUpdating beta...\")\n",
    "        beta_inv = 0\n",
    "        for(int i = 0; i < N; i++):\n",
    "            for(int j = 0; j < K; j++):\n",
    "                phi = phiMatrix.getRow(j).transpose()\n",
    "                beta_inv += R_old.get(j,i) * W.mmul(phi).squaredDistance(dataVectors.get(i))\n",
    "            \n",
    "        beta_inv /= (D * N)\n",
    "        \n",
    "        beta = 1.0 / beta_inv\n",
    "        print(\"done\")\n",
    "    \n",
    "    def WriteDataVectors(dataVectors, filename):\n",
    "        try:\n",
    "            writer = new BufferedWriter( new FileWriter(filename) )\n",
    "            for(DataVector vector : dataVectors):\n",
    "                writer.write(vector.GetLabel() + \" \")\n",
    "                values = vector.getValues()\n",
    "                for(int i = 0; i < values.length; i++):\n",
    "                    writer.write(values[i]+\" \")\n",
    "                writer.write(\"\\n\")\n",
    "                    \n",
    "            writer.close()\n",
    "            \n",
    "        catch IOException e:\n",
    "            print(e)\n",
    "\n",
    "    \n",
    "    \n",
    "    def WritePosteriorDistribution(data, filename):\n",
    "        R = CalculateR(W, beta, data)\n",
    "        values = new HashMap<Integer, Double>()\n",
    "        writer = null\n",
    "        try:\n",
    "            writer = new BufferedWriter(new FileWriter(filename))\n",
    "        catch IOException e:\n",
    "            print(e)\n",
    "            return\n",
    "        \n",
    "        for(int i = 0; i < K; i++):\n",
    "            values.clear()\n",
    "            for(int n = 0; n < data.size(); n++):\n",
    "                label = data.get(n).GetLabel()\n",
    "                if(!values.containsKey(label)):\n",
    "                    values.put(label, 0.0)\n",
    "                \n",
    "                value = values.get(label)\n",
    "                value += R.get(i,n)\n",
    "                \n",
    "                values.put(label, value )\n",
    "                \n",
    "\n",
    "            for(int label : values.keySet()):\n",
    "                center = latentSpaceSamplePoints[i]\n",
    "                try:    \n",
    "                    writer.write(label+\" \")\n",
    "                    writer.write(values.get(label) / data.size()+\" \")\n",
    "                    for(int l = 0; l < L; l++):\n",
    "                        writer.write(center.get(l)+\" \")\n",
    "                    writer.write(\"\\n\")\n",
    "                    \n",
    "                catch IOException e:\n",
    "                    print(e)\n",
    "                    return\n",
    "         \n",
    "        try:\n",
    "            writer.close()\n",
    "        catch IOException e:\n",
    "            print(e)\n",
    "\n",
    "    \n",
    "    class ParameterInitializer implements OptimizationProblem:\n",
    "\n",
    "        \"\"\"\n",
    "         * \n",
    "         * @param gtm\n",
    "         * @param n\n",
    "         *            number of the subset of training vectors to use for\n",
    "         *            parameter initialization. Not all training vectors are\n",
    "         *            needed; using a subsample increases speed\n",
    "        \"\"\"\n",
    "        def __init__(self, GTM gtm, n):\n",
    "\n",
    "            \n",
    "            self.gtm = None\n",
    "            self.n = 0\n",
    "            self.inversePCA = None\n",
    "            self.transformedLatentSamplePoints = None\n",
    "\n",
    "            \n",
    "            \n",
    "            self.gtm = gtm;\n",
    "            self.n = n;\n",
    "            \n",
    "            PCA pca = new PCA(gtm.data.subList(0, n));\n",
    "\n",
    "            inversePCA = pca.getTransform(L).transpose();\n",
    "            transformedLatentSamplePoints = new ArrayList<DoubleMatrix>();\n",
    "            for(DoubleMatrix point : gtm.latentSpaceSamplePoints)\n",
    "                transformedLatentSamplePoints.add(inversePCA.mmul(point));\n",
    "            \n",
    "//            NormalizeTransformedLatentSamplePoints();\n",
    "            \n",
    "        }\n",
    "        \n",
    "        private void NormalizeTransformedLatentSamplePoints(){\n",
    "            double [] max = new double[gtm.D];\n",
    "            double [] min = new double[gtm.D];\n",
    "            double [] mean = new double[gtm.D];\n",
    "            for(int i = 0; i < max.length; i++){\n",
    "                max[i] = Double.MIN_VALUE;\n",
    "                min[i] = Double.MAX_VALUE;\n",
    "            }\n",
    "            for(DoubleMatrix point : transformedLatentSamplePoints)\n",
    "                for(int i = 0; i < gtm.D; i++){\n",
    "                    mean[i] += point.get(i);\n",
    "                    if(Math.abs(point.get(i)) > max[i])\n",
    "                        max[i] = Math.abs(point.get(i));\n",
    "                    if(Math.abs(point.get(i)) < min[i])\n",
    "                        min[i] = Math.abs(point.get(i));\n",
    "                }\n",
    "            double [] norms = new double[gtm.D];\n",
    "            for(int i = 0; i < gtm.D; i++){\n",
    "                norms[i] = max[i] - min [i];\n",
    "                mean[i] /= transformedLatentSamplePoints.size();\n",
    "            }\n",
    "            \n",
    "            \n",
    "            for(DoubleMatrix point : transformedLatentSamplePoints)\n",
    "                for(int i = 0; i < gtm.D; i++){\n",
    "                    double value = point.get(i);\n",
    "                    point.put(i, (value - mean[i])/ (norms[i] / 2) + mean[i]) ;\n",
    "                }\n",
    "                    \n",
    "                \n",
    "        }\n",
    "\n",
    "        /**\n",
    "         * x contains the elements of W\n",
    "         */\n",
    "        @Override\n",
    "        public double Function(DoubleMatrix x) {\n",
    "\n",
    "            DoubleMatrix W = new DoubleMatrix(D,M);\n",
    "            for(int i = 0; i < D; i++)\n",
    "                for(int j = 0; j < M; j++)\n",
    "                    W.put(i, j, x.get(i * M + j));\n",
    "            \n",
    "            double total = 0.0;\n",
    "            //Loop over all latent space sample points\n",
    "            for(int i = 0; i < K; i++){\n",
    "                DoubleMatrix transformedLatentSpaceSamplePoint = transformedLatentSamplePoints.get(i);\n",
    "                total += W.mmul(gtm.phiMatrix.getRow(i).transpose()).distance2(transformedLatentSpaceSamplePoint );\n",
    "            }\n",
    "            return .5 * total / gtm.K; // / gtm.M;\n",
    "        }\n",
    "\n",
    "        @Override\n",
    "        public DoubleMatrix Gradient(DoubleMatrix x) {\n",
    "            DoubleMatrix W = new DoubleMatrix(D,M);\n",
    "            for(int i = 0; i < D; i++)\n",
    "                for(int j = 0; j < M; j++)\n",
    "                    W.put(i, j, x.get(i * M + j));\n",
    "            DoubleMatrix gradient = new DoubleMatrix(D*M);\n",
    "            DoubleMatrix vector = new DoubleMatrix(D*M);\n",
    "            for(int i = 0; i < K; i++){\n",
    "                DoubleMatrix phi = gtm.phiMatrix.getRow(i).transpose();\n",
    "                DoubleMatrix Ux = transformedLatentSamplePoints.get(i);\n",
    "                DoubleMatrix Wphi = W.mmul(phi);\n",
    "                double denominator = Wphi.distance2(Ux);\n",
    "                //D x M\n",
    "                for(int j = 0 ; j < D * M; j++){\n",
    "                    int a = j / M;\n",
    "                    int b = j % M;\n",
    "                    \n",
    "                    vector.put(j, .5*phi.get(b)*( Wphi.get(a) - Ux.get(a) ) / denominator);\n",
    "                    \n",
    "                }\n",
    "                gradient.addi(vector);\n",
    "            }\n",
    "            \n",
    "            return gradient;\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    \n",
    "    private static void test1(){\n",
    "        List<DataVector> data = new ArrayList<DataVector>();\n",
    "        Random rand = new Random();\n",
    "        int N = 10000;\n",
    "        for (int i = 0; i < N; i++){\n",
    "            double x = rand.nextDouble();\n",
    "            double y = x + ( rand.nextDouble() - .5 ) / .5 * .01;\n",
    "            double [] values = {x,y};\n",
    "            data.add(new DataVector(values));\n",
    "            \n",
    "        }\n",
    "        //Initialize the GTM\n",
    "        GTM gtm = new GTM(data, 1);\n",
    "        System.out.println(\"df\");\n",
    "        gtm.setSigma(.01);\n",
    "        gtm.setK(200);\n",
    "        gtm.setM(2);\n",
    "        gtm.InitializeModel();\n",
    "\n",
    "        List<DoubleMatrix> testingData = new ArrayList<DoubleMatrix>();\n",
    "        for (int i = 0; i < 1000; i++){\n",
    "            double x = rand.nextDouble();\n",
    "            double y = x + ( rand.nextDouble() - .5 ) / .5 * .01;\n",
    "            double [] values = {x};\n",
    "            DoubleMatrix latentPoint = new DoubleMatrix(values);\n",
    "            \n",
    "            testingData.add(latentPoint);\n",
    "        }\n",
    "        \n",
    "        \n",
    "        //Create a PCA transform from latent to data space:\n",
    "        PCA pca = new PCA(data.subList(0, 1000));\n",
    "        DoubleMatrix inversePCA = pca.getTransform(2).transpose();\n",
    "\n",
    "        //First test PCA.  Write stuff to \"pca.txt\"\n",
    "        try{\n",
    "            BufferedWriter pcaWriter = new BufferedWriter(new FileWriter(\"pca.txt\"));\n",
    "\n",
    "            for(int i = 0; i < 1000; i++){\n",
    "                DoubleMatrix dataSpaceProjectionPCA = inversePCA.mmul(testingData.get(i));\n",
    "                for(int j = 0; j < dataSpaceProjectionPCA.rows; j++)\n",
    "                    pcaWriter.write(dataSpaceProjectionPCA.get(j)+\" \");\n",
    "                pcaWriter.write('\\n');\n",
    "                \n",
    "        }\n",
    "            pcaWriter.close();\n",
    "            BufferedWriter gtmWriter = new BufferedWriter(new FileWriter(\"gtm.txt\"));\n",
    "            for(int i = 0; i < 1000; i++){\n",
    "                DoubleMatrix dataSpaceProjectionGTM = gtm.ProjectToDataSpace(testingData.get(i));\n",
    "                for(int j = 0; j < dataSpaceProjectionGTM.rows; j++)\n",
    "                    gtmWriter.write(dataSpaceProjectionGTM.get(j)+\" \");\n",
    "                gtmWriter.write('\\n');\n",
    "            }\n",
    "            gtmWriter.close();\n",
    "        }catch(IOException e){\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "        \n",
    "        //Now perform a single step of the EM aglorithm\n",
    "        \n",
    "        gtm.PerformEMStep();\n",
    "        \n",
    "    }\n",
    "    private static void test2(String [] argv){\n",
    "        \n",
    "        \n",
    "        String dataFile = argv[0];\n",
    "        List<DataVector> data = new ArrayList<DataVector>();\n",
    "        //Read data in\n",
    "        try{\n",
    "            BufferedReader reader = new BufferedReader(new FileReader(dataFile));\n",
    "            String line = \"\";\n",
    "            while((line = reader.readLine()) != null){\n",
    "                String [] elements = line.split(\"\\\\s+\");\n",
    "                double [] values = new double[elements.length - 1];\n",
    "                for(int i = 1; i < elements.length; i++)\n",
    "                    values[i-1] = Double.valueOf(elements[i]);\n",
    "                DataVector vector = new DataVector(values);\n",
    "                vector.SetLabel(Integer.valueOf(elements[0]));\n",
    "                data.add(vector);\n",
    "            }\n",
    "                \n",
    "            reader.close();\n",
    "        }catch(IOException e){\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "        \n",
    "        GTM gtm = new GTM(data,2);\n",
    "        gtm.setSigma(Double.valueOf(argv[1])); //.5\n",
    "        gtm.setK(Integer.valueOf(argv[2])); //50\n",
    "        gtm.setM(Integer.valueOf(argv[3]));    //4\n",
    "        gtm.InitializeModel();\n",
    "        System.out.print(\"Writing pca transformed latent space sample points...\");\n",
    "        PCA pca = new PCA(data);\n",
    "        DoubleMatrix inversePCA = pca.getTransform(2).transpose();\n",
    "        List<DataVector> transformedSamplePoints = new ArrayList<DataVector>();\n",
    "        for(DoubleMatrix vector : gtm.latentSpaceSamplePoints){\n",
    "            DataVector dv = new DataVector( inversePCA.mmul(vector).toArray() );\n",
    "            \n",
    "            transformedSamplePoints.add(dv);\n",
    "        }\n",
    "        String baseName = \"gtm_output/\";\n",
    "        \n",
    "        gtm.WriteDataVectors(transformedSamplePoints, baseName+\"transformed_sample_points.txt\");\n",
    "        System.out.println(\"done\");\n",
    "        int N = 1000;\n",
    "        \n",
    "        for(int i = 0; i < N; i++){\n",
    "//            System.out.println(gtm.W);\n",
    "            List<DataVector> projection = gtm.ProjectDataToLatentSpace();\n",
    "            \n",
    "            \n",
    "            gtm.WriteDataVectors(projection, baseName+String.format(\"%03d\", i)+\".txt\");\n",
    "            gtm.WritePosteriorDistribution(projection, baseName+String.format(\"prior/%03d\", i)+\".txt\");\n",
    "            \n",
    "            //Look at how latent sample points transform\n",
    "            transformedSamplePoints.clear();\n",
    "            System.out.print(\"Projecting latent space sample points to data space...\");\n",
    "            for(DoubleMatrix vector : gtm.latentSpaceSamplePoints){\n",
    "                DoubleMatrix phi = gtm.CalculatePhiVector( vector );\n",
    "                DataVector dv = new DataVector( gtm.W.mmul(phi).toArray() );\n",
    "                \n",
    "                transformedSamplePoints.add(dv);\n",
    "            }\n",
    "            System.out.println(\"done.\");\n",
    "            \n",
    "            gtm.WriteDataVectors(transformedSamplePoints, baseName+\"latent/\"+String.format(\"%03d\", i)+\".txt\");\n",
    "            System.out.println(\"Performing EM step!\");\n",
    "            System.out.println(gtm.beta);\n",
    "            gtm.PerformEMStep();\n",
    "        }\n",
    "        \n",
    "        \n",
    "    }\n",
    "    public static void main(String [] argv){\n",
    "        \n",
    "        test2(argv);\n",
    "        \n",
    "        \n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.michigan.gevirtz.latent;\n",
    "\n",
    "\n",
    "import java.io.BufferedReader;\n",
    "import java.io.FileReader;\n",
    "import java.io.IOException;\n",
    "import java.util.ArrayList;\n",
    "import java.util.Collections;\n",
    "import java.util.Comparator;\n",
    "import java.util.List;\n",
    "\n",
    "import org.jblas.ComplexDoubleMatrix;\n",
    "import org.jblas.DoubleMatrix;\n",
    "import org.jblas.Eigen;\n",
    "\n",
    "import edu.michigan.gevirtz.data.DataVector;\n",
    "\n",
    "public class PCA {\n",
    "\n",
    "\n",
    "    private DoubleMatrix dataMatrix = null;\n",
    "\n",
    "    private DoubleMatrix covarianceMatrix = null;\n",
    "    \n",
    "    private DoubleMatrix eigenVectors = null;\n",
    "    \n",
    "    private DoubleMatrix eigenValues = null;\n",
    "    \n",
    "    private void BuildCovarianceMatrix(){\n",
    "        \n",
    "        //dataMatrix.columns is the number of variables there are per data vector\n",
    "        double [][] result = new double[dataMatrix.columns][dataMatrix.columns];\n",
    "        \n",
    "        int N = dataMatrix.rows;\n",
    "        \n",
    "        for(int i = 0; i < dataMatrix.columns; i++)\n",
    "            for(int j = 0; j < dataMatrix.columns; j++){\n",
    "                \n",
    "                double total = 0;\n",
    "                for(int k = 0; k < dataMatrix.rows; k++)\n",
    "                    total += dataMatrix.get(k,i) * dataMatrix.get(k,j);  \n",
    "\n",
    "                result[i][j] = total / ( N - 1);\n",
    "                result[j][i] = total / ( N - 1);\n",
    "                \n",
    "            }\n",
    "        \n",
    "        covarianceMatrix = new DoubleMatrix(result);\n",
    "        \n",
    "        \n",
    "    }\n",
    "    \n",
    "    \n",
    "    public void CalculatePCA(){\n",
    "        \n",
    "        DoubleMatrix values = Eigen.eigenvectors(covarianceMatrix)[1].real();\n",
    "        DoubleMatrix  vectors = Eigen.eigenvectors(covarianceMatrix)[0].real();\n",
    "        \n",
    "\n",
    "//        System.out.println(covarianceMatrix);\n",
    "        List<EigenVectorEigenValuePair> pairs = new ArrayList<PCA.EigenVectorEigenValuePair>();\n",
    "        for(int i = 0; i < vectors.columns; i++){\n",
    "            pairs.add( new EigenVectorEigenValuePair(vectors.getColumn(i), values.get(i,i)));\n",
    "//            System.out.println(\"Eigenvector: \"+vectors.getColumn(i));\n",
    "        }\n",
    "        \n",
    "        Collections.sort(pairs, pairs.get(0).comparator);\n",
    "        \n",
    "        //Create the column vector that will contain the eigenvalues\n",
    "        eigenValues = new DoubleMatrix(pairs.size());\n",
    "        //Fill the structures holding eigenvectors and eigenvalues\n",
    "        int index = 0;\n",
    "        for(EigenVectorEigenValuePair pair : pairs){\n",
    "            \n",
    "            //if eigenVectors is null, we need to add the first of the eigenvectors.\n",
    "            if(eigenVectors == null){\n",
    "                eigenVectors = pair.eigenvector.dup();\n",
    "                continue;\n",
    "            }\n",
    "            //Otherwise, stick the next eigenvector at the end of the matrix\n",
    "            eigenVectors = DoubleMatrix.concatHorizontally(eigenVectors, pair.eigenvector);\n",
    "            eigenValues.put(index,0,pair.eigenvalue);\n",
    "            index++;\n",
    "            \n",
    "            \n",
    "            \n",
    "        }\n",
    "//        System.out.println(\"eigenValues: \"+eigenValues);\n",
    "        \n",
    "    }\n",
    "    \n",
    "    public double GetLargestEigenvalue(){\n",
    "        return eigenValues.get(0,0);\n",
    "    }\n",
    "        \n",
    "    private void BuildDataMatrix(List<DataVector> data){\n",
    "\n",
    "        int N = data.size();\n",
    "        \n",
    "        double [][] dataArray = new double[N][];\n",
    "        \n",
    "        for(int i = 0; i < data.size(); i++)\n",
    "            dataArray[i] = data.get(i).getValues();\n",
    "            \n",
    "        \n",
    "        dataMatrix = new DoubleMatrix(dataArray);\n",
    "        \n",
    "        //Subtract means\n",
    "        DoubleMatrix columnMeans = dataMatrix.columnMeans();\n",
    "        dataMatrix.subiRowVector(columnMeans);\n",
    "    }\n",
    "    \n",
    "    public List<DataVector> transform(){\n",
    "        \n",
    "        List<DataVector> result = new ArrayList<DataVector>();\n",
    "        DoubleMatrix product = eigenVectors.transpose().mmul( dataMatrix.transpose() );\n",
    "\n",
    "        for(int i = 0; i < product.columns; i++){\n",
    "            result.add( new DataVector(product.getColumn(i).toArray()) );\n",
    "        }\n",
    "        \n",
    "        return result;\n",
    "        \n",
    "    }\n",
    "    public List<DataVector> transform(List<DataVector> data, int L){\n",
    "        \n",
    "        List<DataVector> result = new ArrayList<DataVector>();\n",
    "        \n",
    "        DoubleMatrix transformation = getTransform(L);\n",
    "        \n",
    "        for(DataVector dataVector : data){\n",
    "            DoubleMatrix vector = new DoubleMatrix(dataVector.getValues());\n",
    "            DataVector newDataVector = new DataVector(transformation.mmul(vector).toArray());\n",
    "            newDataVector.SetLabel( dataVector.GetLabel() );\n",
    "            \n",
    "            result.add(newDataVector);\n",
    "            \n",
    "        }\n",
    "        \n",
    "        return result;\n",
    "        \n",
    "    }\n",
    "    \n",
    "    public PCA(List<DataVector> data){\n",
    "        \n",
    "        BuildDataMatrix(data);\n",
    "        \n",
    "        BuildCovarianceMatrix();\n",
    "        \n",
    "        CalculatePCA();\n",
    "        \n",
    "    }\n",
    "    \n",
    "    public DoubleMatrix getTransform(int L){\n",
    "        \n",
    "        int rows = eigenVectors.rows;\n",
    "        \n",
    "        return eigenVectors.getRange(0,rows,0,L).transpose();\n",
    "        \n",
    "    }\n",
    "    \n",
    "    private class EigenVectorEigenValuePair{\n",
    "        private Comparator<EigenVectorEigenValuePair> comparator = new Comparator<PCA.EigenVectorEigenValuePair>() {\n",
    "            \n",
    "            @Override\n",
    "            public int compare(EigenVectorEigenValuePair o1,\n",
    "                    EigenVectorEigenValuePair o2) {\n",
    "                // TODO Auto-generated method stub\n",
    "                double val = (o2.eigenvalue - o1.eigenvalue); \n",
    "                return (int)(val / Math.abs(val));\n",
    "            }\n",
    "        };\n",
    "        \n",
    "        public double eigenvalue = 0;\n",
    "        public DoubleMatrix eigenvector = null;\n",
    "        \n",
    "        public EigenVectorEigenValuePair(DoubleMatrix eigenvector, double eigenvalue){\n",
    "            self.eigenvalue = eigenvalue;\n",
    "            self.eigenvector = eigenvector;\n",
    "        }\n",
    "        \n",
    "    }\n",
    "    \n",
    "    \n",
    "    //Simple test to be run from commandline.  Loads file supplied as arg[0], reads data vectors, spits out PCA-transformed vectors\n",
    "    public static void main(String [] args){\n",
    "        \n",
    "        List<DataVector> data = new ArrayList<DataVector>();\n",
    "        \n",
    "        try{\n",
    "            BufferedReader reader = new BufferedReader( new FileReader(args[0]) );\n",
    "            String line;\n",
    "            while((line = reader.readLine()) != null){\n",
    "                String [] elements  = line.split(\"\\\\s+\");\n",
    "                double [] values = new double[elements.length];;\n",
    "                for(int i = 1; i < elements.length; i++)\n",
    "                    values[i] = Double.valueOf(elements[i]);\n",
    "                DataVector dataVector = new DataVector( values ) ;\n",
    "                dataVector.SetLabel(Integer.valueOf(elements[0]));\n",
    "                data.add( dataVector );\n",
    "            }\n",
    "            \n",
    "            reader.close();\n",
    "        }catch(IOException e){\n",
    "            e.printStackTrace();\n",
    "            System.exit(1);\n",
    "        }\n",
    "        \n",
    "        PCA pca = new PCA(data);\n",
    "        for(DataVector dataVector : pca.transform(data, 2)){\n",
    "            double [] values = dataVector.getValues();\n",
    "            System.out.print(dataVector.GetLabel()+\" \");\n",
    "            for(double value : values)\n",
    "                System.out.print( value +\" \");\n",
    "            System.out.println();\n",
    "        }\n",
    "            \n",
    "        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
